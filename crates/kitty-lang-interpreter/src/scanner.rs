use crate::tokens::{InvalidTokenReason, Token};

/// Represents a tokenized sequence of characters generated by the scanner.
#[derive(Debug, PartialEq)]
pub struct Lexeme {
    /// Token representing the lexeme.
    pub token: Token,
    /// Index of the first character for the lexeme in the source str.
    pub index: usize,
    /// Number of characters in the lexeme.
    pub length: usize,
}

pub struct Scanner<'a> {
    _source: &'a str,
    chars: std::iter::Peekable<std::str::Chars<'a>>,
    start_i: usize,
    current_i: usize,
}

impl<'a> Scanner<'a> {
    pub fn new(source: &'a str) -> Self {
        Self {
            _source: source,
            chars: source.chars().peekable(),
            start_i: 0,
            current_i: 0,
        }
    }

    fn make_lexeme(&self, token: Token) -> Lexeme {
        Lexeme {
            token,
            index: self.start_i,
            length: self.current_i - self.start_i + 1,
        }
    }

    fn make_invalid_lexeme(&mut self, reason: InvalidTokenReason) -> Lexeme {
        // TODO: consume until a valid token is found.
        // VALID_TOKENS = [' ', '\n', '+', ...]
        self.make_lexeme(Token::Invalid(reason))
    }

    fn try_consume_char(&mut self, expected: char) -> bool {
        if let Some(c) = self.chars.peek() {
            if *c == expected {
                self.advance();

                return true;
            }
        }

        false
    }

    fn consume_while<F: Fn(char) -> bool>(&mut self, f: F) {
        while let Some(c) = self.chars.peek() {
            if !f(*c) {
                break;
            }
            self.advance();
        }
    }

    // Advance the scanner forward one character while continuing to read the
    // current lexeme.
    fn advance(&mut self) {
        self.current_i += 1;
        assert!(self.chars.next().is_some());
    }
}

impl Iterator for Scanner<'_> {
    type Item = Lexeme;

    fn next(&mut self) -> Option<Self::Item> {
        // Skip whitespace.
        self.consume_while(is_delim_char);

        // Try to read the first character of the next lexeme.
        self.start_i = self.current_i;

        if let Some(c) = self.chars.next() {
            let lexeme = match c {
                '(' => Some(self.make_lexeme(Token::LeftParen)),
                ')' => Some(self.make_lexeme(Token::RightParen)),
                '{' => Some(self.make_lexeme(Token::LeftBrace)),
                '}' => Some(self.make_lexeme(Token::RightBrace)),
                '[' => Some(self.make_lexeme(Token::LeftBracket)),
                ']' => Some(self.make_lexeme(Token::RightBracket)),
                ';' => Some(self.make_lexeme(Token::Semicolon)),
                ',' => Some(self.make_lexeme(Token::Comma)),
                '.' => Some(self.make_lexeme(Token::Period)),
                '-' => {
                    if self
                        .chars
                        .peek()
                        .map(|c| c.is_ascii_digit())
                        .unwrap_or(false)
                    {
                        Some(self.scan_rest_of_number())
                    } else {
                        Some(self.make_lexeme(Token::Minus))
                    }
                }
                '+' => Some(self.make_lexeme(Token::Plus)),
                '*' => Some(self.make_lexeme(Token::Star)),
                '/' => {
                    if self.try_consume_char('/') {
                        // Consume the rest of the line for the comment.
                        self.consume_while(|c| c != '\n');
                        Some(self.make_lexeme(Token::Comment))
                    } else {
                        Some(self.make_lexeme(Token::Slash))
                    }
                }
                '=' => {
                    if self.try_consume_char('=') {
                        Some(self.make_lexeme(Token::EqualEqual))
                    } else {
                        Some(self.make_lexeme(Token::Equal))
                    }
                }
                '<' => {
                    if self.try_consume_char('=') {
                        Some(self.make_lexeme(Token::LessEqual))
                    } else {
                        Some(self.make_lexeme(Token::Less))
                    }
                }
                '>' => {
                    if self.try_consume_char('=') {
                        Some(self.make_lexeme(Token::GreaterEqual))
                    } else {
                        Some(self.make_lexeme(Token::Greater))
                    }
                }
                '!' => {
                    if self.try_consume_char('=') {
                        Some(self.make_lexeme(Token::BangEqual))
                    } else {
                        Some(self.make_invalid_lexeme(InvalidTokenReason::BangNotSupported))
                    }
                }
                '"' => Some(self.scan_rest_of_string()),
                c if c.is_ascii_digit() => Some(self.scan_rest_of_number()),
                c if is_ident_lead_char(c) => Some(self.scan_start_of_identifier(c)),
                _ => Some(self.make_invalid_lexeme(InvalidTokenReason::UnknownChars)),
            };

            self.current_i += 1;

            lexeme
        } else {
            None
        }
    }
}

impl Scanner<'_> {
    fn scan_rest_of_string(&mut self) -> Lexeme {
        self.consume_while(|c| c != '"');

        if self.chars.peek().is_none() {
            self.make_invalid_lexeme(InvalidTokenReason::UnterminatedString)
        } else {
            // Eat the closing quote.
            self.advance();
            self.make_lexeme(Token::String)
        }
    }

    fn scan_rest_of_number(&mut self) -> Lexeme {
        self.consume_while(|c| c.is_ascii_digit());

        if self.chars.peek() == Some(&'.') {
            self.advance();
            self.consume_while(|c| c.is_ascii_digit());

            // Numbers must have a delimiter following the last character.
            if self.chars.peek().map(|c| is_delim_char(*c)).unwrap_or(true) {
                self.make_lexeme(Token::Float)
            } else {
                self.advance();
                self.make_invalid_lexeme(InvalidTokenReason::UnknownNumberChars)
            }
        } else {
            // Numbers must have a delimiter following the last character.
            if self.chars.peek().map(|c| is_delim_char(*c)).unwrap_or(true) {
                self.make_lexeme(Token::Int)
            } else {
                self.advance();
                self.make_invalid_lexeme(InvalidTokenReason::UnknownNumberChars)
            }
        }
    }

    fn scan_start_of_identifier(&mut self, first_char: char) -> Lexeme {
        match first_char {
            'a' => self.scan_maybe_keyword("and", 1, Token::And),
            'b' => self.scan_maybe_keyword("break", 1, Token::Break),
            'c' => match self.chars.peek() {
                Some(&'o') => {
                    self.advance();

                    match self.chars.peek() {
                        Some(&'n') => {
                            self.advance();

                            match self.chars.peek() {
                                Some(&'s') => self.scan_maybe_keyword("const", 3, Token::Const),
                                Some(&'t') => {
                                    self.scan_maybe_keyword("continue", 3, Token::Continue)
                                }
                                _ => self.make_lexeme(Token::Identifier),
                            }
                        }
                        _ => self.make_lexeme(Token::Identifier),
                    }
                }
                _ => self.make_lexeme(Token::Identifier),
            },
            'e' => self.scan_maybe_keyword("else", 1, Token::Else),
            'f' => match self.chars.peek() {
                Some('a') => self.scan_maybe_keyword("false", 1, Token::False),
                Some('o') => self.scan_maybe_keyword("for", 1, Token::For),
                Some('n') => self.scan_maybe_keyword("fn", 1, Token::Fn),
                _ => self.make_lexeme(Token::Identifier),
            },
            'i' => self.scan_maybe_keyword("if", 1, Token::If),
            'n' => match self.chars.peek() {
                Some('o') => self.scan_maybe_keyword("not", 1, Token::Not),
                Some('u') => self.scan_maybe_keyword("null", 1, Token::Null),
                _ => self.make_lexeme(Token::Identifier),
            },
            'o' => self.scan_maybe_keyword("or", 1, Token::Or),
            't' => self.scan_maybe_keyword("true", 1, Token::True),
            'r' => self.scan_maybe_keyword("return", 1, Token::Return),
            'v' => self.scan_maybe_keyword("var", 1, Token::Var),
            'w' => self.scan_maybe_keyword("while", 1, Token::While),
            _ => {
                self.consume_while(|c| c.is_ascii_alphanumeric() || c == '_');
                self.make_lexeme(Token::Identifier)
            }
        }
    }

    fn scan_maybe_keyword(&mut self, keyword_name: &str, skip: usize, token: Token) -> Lexeme {
        // Scan forward and make sure the next set of chars match `keyword_name`.
        // If it does not match then the lexeme is an identifier.
        for keyword_c in keyword_name.chars().skip(skip) {
            if self.chars.peek().map(|c| *c != keyword_c).unwrap_or(true) {
                return self.scan_rest_of_identifier();
            }

            self.advance();
        }

        // This is not a keyword if there are additional identifier chars after the keyword match
        // finishes succesfully.
        if self
            .chars
            .peek()
            .map(|c| is_ident_tail_char(*c))
            .unwrap_or(false)
        {
            self.scan_rest_of_identifier()
        } else {
            self.make_lexeme(token)
        }
    }

    fn scan_rest_of_identifier(&mut self) -> Lexeme {
        self.consume_while(is_ident_tail_char);
        self.make_lexeme(Token::Identifier)
    }
}

fn is_delim_char(c: char) -> bool {
    c == ' ' || c == '\t' || c == '\r' || c == '\n'
}

fn is_ident_lead_char(c: char) -> bool {
    c.is_ascii_alphabetic() || c == '_'
}

fn is_ident_tail_char(c: char) -> bool {
    c.is_ascii_alphanumeric() || c == '_'
}
