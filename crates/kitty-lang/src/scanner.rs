use crate::tokens::Token;

/// Represents a tokenized sequence of characters generated by the scanner.
#[derive(Debug, PartialEq)]
pub struct Lexeme {
    /// Token representing the lexeme.
    pub token: Token,
    /// Index of the first character for the lexeme in the source str.
    pub index: usize,
    /// Number of characters in the lexeme.
    pub length: usize,
}

pub struct Scanner<'a> {
    _source: &'a str,
    chars: std::iter::Peekable<std::str::Chars<'a>>,
    start_i: usize,
    current_i: usize,
}

impl<'a> Scanner<'a> {
    pub fn new(source: &'a str) -> Self {
        Self {
            _source: source,
            chars: source.chars().peekable(),
            start_i: 0,
            current_i: 0,
        }
    }

    fn make_lexeme(&self, token: Token) -> Lexeme {
        Lexeme {
            token,
            index: self.start_i,
            length: self.current_i - self.start_i + 1,
        }
    }

    fn try_consume_char(&mut self, expected: char) -> bool {
        if let Some(c) = self.chars.peek() {
            if *c == expected {
                self.advance();

                return true;
            }
        }

        false
    }

    // Advance the scanner forward one character while continuing to read the
    // current lexeme.
    fn advance(&mut self) {
        self.current_i += 1;
        assert!(self.chars.next().is_some());
    }
}

impl Iterator for Scanner<'_> {
    type Item = Lexeme;

    fn next(&mut self) -> Option<Self::Item> {
        // Skip whitespace.
        while let Some(c) = self.chars.peek() {
            if *c == ' ' || *c == '\t' || *c == '\r' || *c == '\n' {
                self.advance();
            } else {
                break;
            }
        }

        // Try to read the first character of the next lexeme.
        self.start_i = self.current_i;

        if let Some(c) = self.chars.next() {
            let lexeme = match c {
                '(' => Some(self.make_lexeme(Token::LeftParen)),
                ')' => Some(self.make_lexeme(Token::RightParen)),
                '{' => Some(self.make_lexeme(Token::LeftBrace)),
                '}' => Some(self.make_lexeme(Token::RightBrace)),
                '[' => Some(self.make_lexeme(Token::LeftBracket)),
                ']' => Some(self.make_lexeme(Token::RightBracket)),
                ';' => Some(self.make_lexeme(Token::Semicolon)),
                ',' => Some(self.make_lexeme(Token::Comma)),
                '.' => Some(self.make_lexeme(Token::Period)),
                '-' => Some(self.make_lexeme(Token::Minus)),
                '+' => Some(self.make_lexeme(Token::Plus)),
                '*' => Some(self.make_lexeme(Token::Star)),
                '/' => Some(self.make_lexeme(Token::Slash)),
                '=' => {
                    if self.try_consume_char('=') {
                        Some(self.make_lexeme(Token::EqualEqual))
                    } else {
                        Some(self.make_lexeme(Token::Equal))
                    }
                }
                '<' => {
                    if self.try_consume_char('=') {
                        Some(self.make_lexeme(Token::LessEqual))
                    } else {
                        Some(self.make_lexeme(Token::Less))
                    }
                }
                '>' => {
                    if self.try_consume_char('=') {
                        Some(self.make_lexeme(Token::GreaterEqual))
                    } else {
                        Some(self.make_lexeme(Token::Greater))
                    }
                }
                '!' => {
                    if self.try_consume_char('=') {
                        Some(self.make_lexeme(Token::BangEqual))
                    } else {
                        Some(self.make_lexeme(Token::Bang))
                    }
                }
                _ => Some(self.make_lexeme(Token::Invalid)),
            };

            self.current_i += 1;

            lexeme
        } else {
            None
        }
    }
}
